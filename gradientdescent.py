#Linear Hypothesis Function
'''
h(x) = m0 + m1x
'''
# Task: Parameters of our model are: m0 and m1. Adjust these values to minimize cost function
# Training Data Part
# xi => yi

# batch gradient algorithm
# each iteration performs the update
"""
cost_function(j(m)) = 1/m(âˆ‘ from i to m)((hm)(x^i) - y^i)^2
"""
